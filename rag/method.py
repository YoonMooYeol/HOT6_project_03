from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_community.document_loaders import CSVLoader
import os
from glob import glob
import uuid
import pickle
from .models import RAG_DB
import asyncio
from typing import List
from langchain.prompts import ChatPromptTemplate
from django.conf import settings
from tqdm import tqdm

from dotenv import load_dotenv

load_dotenv()

class RAGProcessor:
    TEMP_DIR = "data/temp_embeddings"
    DB_DIR = os.path.join(settings.BASE_DIR, "embeddings", "chroma_db")

    @staticmethod
    def load_and_preprocess_csv(csv_pattern):
        """CSV íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ë°˜í™˜."""
        csv_files = glob(csv_pattern)
        if not csv_files:
            print(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_pattern}")
            return None
        print(f"ì²˜ë¦¬í•  CSV íŒŒì¼: {len(csv_files)}ê°œ")
        for file in csv_files:
            print(f"- {file}")
        return csv_files

    @staticmethod
    def filter_processed_files(csv_files):
        """ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì„ ì œì™¸í•˜ê³  ìƒˆë¡œìš´ íŒŒì¼ ëª©ë¡ë§Œ ë°˜í™˜."""
        processed_files = set(RAG_DB.objects.values_list('file_path', flat=True))
        new_files = [f for f in csv_files if f not in processed_files]
        print(f"ì²˜ë¦¬í•  ìƒˆë¡œìš´ CSV íŒŒì¼: {len(new_files)}ê°œ")
        return new_files

    @staticmethod
    def initialize_chroma_db():
        """Chroma DBë¥¼ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ê¸°ì¡´ DBë¥¼ ë¡œë“œ."""
        db_dir = RAGProcessor.DB_DIR
        print("\n=== Chroma DB ìƒíƒœ ===")
        print(f"ì‚¬ìš© ì¤‘ì¸ DB ê²½ë¡œ: {db_dir}")
        print(f"ì ˆëŒ€ ê²½ë¡œ: {os.path.abspath(db_dir)}")
        
        # DB íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if os.path.exists(f"{db_dir}/chroma.sqlite3"):
            print(f"chroma.sqlite3 íŒŒì¼ í¬ê¸°: {os.path.getsize(f'{db_dir}/chroma.sqlite3')} bytes")
        
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small", chunk_size=1000)

        if os.path.exists(db_dir) and os.path.exists(f"{db_dir}/chroma.sqlite3"):
            print("ê¸°ì¡´ Chroma DB ë¡œë“œ ì¤‘...")
            vectorstore = Chroma(
                persist_directory=db_dir,
                embedding_function=embeddings,
                collection_name="korean_dialogue"
            )
            existing_ids = set(vectorstore._collection.get()['ids'])
            print(f"ê¸°ì¡´ ë¬¸ì„œ ìˆ˜: {len(existing_ids)}")
        else:
            print("ìƒˆë¡œìš´ Chroma DB ìƒì„±")
            vectorstore = None
            existing_ids = set()

        return vectorstore, existing_ids

    @staticmethod
    def load_csv_with_metadata(csv_file):
        """CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë©”íƒ€ë°ì´í„° ì—´ì„ ì¶”ê°€."""
        print(f"\níŒŒì¼ ì²˜ë¦¬ ì¤‘: {csv_file}")
        loader = CSVLoader(file_path=csv_file, metadata_columns=['emotion'])
        return loader.load()

    @staticmethod
    def filter_new_documents(docs, existing_ids, csv_file):
        """ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë¬¸ì„œë¥¼ ì œì™¸í•˜ê³  ìƒˆ ë¬¸ì„œë§Œ í•„í„°ë§."""
        new_docs = []
        for idx, doc in enumerate(docs):
            doc.metadata['source_file'] = os.path.basename(csv_file)
            unique_id = str(uuid.uuid4())
            doc_id = f"doc_{unique_id}_{idx}"
            if doc_id not in existing_ids:
                doc.metadata['doc_id'] = doc_id
                new_docs.append(doc)
        print(f"ìƒˆë¡œìš´ ë¬¸ì„œ ë°œê²¬: {len(new_docs)}ê°œ")
        return new_docs

    @staticmethod
    def split_documents(docs):
        """ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• ."""
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
        splits = text_splitter.split_documents(docs)
        print(f"ë¶„í•  ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬")
        return splits

    @staticmethod
    def prepare_data_for_chroma(splits):
        """Chroma DBì— ì €ì¥í•  í…ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„°, ID ì¤€ë¹„."""
        texts, metadatas, ids = [], [], []
        for doc in splits:
            texts.append(f"content: {doc.page_content}")
            metadatas.append({
                "emotion": doc.metadata.get('emotion', ''),
            })
            ids.append(doc.metadata.get('doc_id'))

        return texts, metadatas, ids

    @staticmethod
    async def create_embeddings_async(texts: List[str], pbar: tqdm) -> List[List[float]]:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ë¹„ë™ê¸°ë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
        embedding_function = OpenAIEmbeddings(
            model="text-embedding-3-small",
            chunk_size=1000
        )
        
        batch_size = 20
        concurrent_tasks = 5
        all_embeddings = []
        batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]
        
        semaphore = asyncio.Semaphore(concurrent_tasks)
        
        async def process_batch(batch):
            async with semaphore:
                await asyncio.sleep(0.1)
                return await embedding_function.aembed_documents(batch)
        
        tasks = [process_batch(batch) for batch in batches]
        
        for coro in asyncio.as_completed(tasks):
            embeddings = await coro
            if embeddings:
                all_embeddings.extend(embeddings)
                pbar.update(batch_size)
        
        return all_embeddings

    @staticmethod
    def create_embeddings(texts: List[str]) -> List[List[float]]:
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë¹„ë™ê¸° ì„ë² ë”© ìƒì„±ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        with tqdm(total=len(texts), desc="ì„ë² ë”© ìƒì„± ì¤‘") as pbar:
            embeddings = asyncio.run(RAGProcessor.create_embeddings_async(texts, pbar))
        return embeddings

    @staticmethod
    def process_files(csv_files: List[str], existing_ids: set, vectorstore, db_dir: str):
        """CSV íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ê³  ì§„í–‰ìƒí™©ì„ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        total_new_docs = 0
        processed_count = 0

        print("\n=== CSV íŒŒì¼ ì²˜ë¦¬ ì‹œì‘ ===")
        for csv_file in tqdm(csv_files, desc="ğŸ“‚ CSV íŒŒì¼ ì²˜ë¦¬"):
            try:
                # CSV íŒŒì¼ ë¡œë“œ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
                docs = RAGProcessor.load_csv_with_metadata(csv_file)
                if not docs:
                    continue

                # ìƒˆ ë¬¸ì„œ í•„í„°ë§
                new_docs = RAGProcessor.filter_new_documents(docs, existing_ids, csv_file)
                if not new_docs:
                    continue

                # ë¬¸ì„œ ë¶„í• 
                total_new_docs += len(new_docs)
                splits = RAGProcessor.split_documents(new_docs)
                
                # ë°ì´í„° ì¤€ë¹„
                texts, metadatas, ids = RAGProcessor.prepare_data_for_chroma(splits)
                
                print(f"\nğŸ“„ [{os.path.basename(csv_file)}] ì²˜ë¦¬ ì¤‘...")
                print(f"   - í…ìŠ¤íŠ¸ ìˆ˜: {len(texts)}ê°œ")
                
                # ì„ì‹œ ì €ì¥ëœ ì„ë² ë”© í™•ì¸
                temp_embeddings = RAGProcessor.load_temp_embeddings(csv_file)
                
                if temp_embeddings is not None:
                    print("ğŸ’¾ ê¸°ì¡´ ì„ì‹œ ì„ë² ë”© ì‚¬ìš©")
                    embeddings = temp_embeddings
                else:
                    print("ğŸ”„ ìƒˆë¡œìš´ ì„ë² ë”© ìƒì„± ì‹œì‘")
                    embeddings = RAGProcessor.create_embeddings(texts)
                    RAGProcessor.save_temp_embeddings(csv_file, embeddings)
                
                # Chroma DB ì—…ë°ì´íŠ¸
                vectorstore = RAGProcessor.update_chroma_db(
                    vectorstore, texts, embeddings, metadatas, ids, db_dir
                )
                
                # ì²˜ë¦¬ ì™„ë£Œ ê¸°ë¡
                RAGProcessor.save_processed_file_info(csv_file)
                processed_count += 1
                print(f"âœ… [{os.path.basename(csv_file)}] ì²˜ë¦¬ ì™„ë£Œ\n")

            except Exception as e:
                print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({os.path.basename(csv_file)}): {e}")
                continue

        return vectorstore, total_new_docs, processed_count

    @staticmethod
    def update_chroma_db(vectorstore, texts, embeddings, metadatas, ids, db_dir):
        """Chroma DBì— ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¶”ê°€í•˜ê³  ì§„í–‰ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
        MAX_BATCH_SIZE = 5000

        if vectorstore is None:
            print("ğŸ”¨ ìƒˆë¡œìš´ Chroma DB ìƒì„± ì¤‘...")
            embedding_function = OpenAIEmbeddings(model="text-embedding-3-small")
            vectorstore = Chroma(
                persist_directory=db_dir,
                embedding_function=embedding_function,
                collection_name="korean_dialogue"
            )

        total_batches = (len(texts) + MAX_BATCH_SIZE - 1) // MAX_BATCH_SIZE
        print(f"ğŸ“¦ Chroma DB ì—…ë°ì´íŠ¸ ì‹œì‘ (ì´ {total_batches}ê°œ ë°°ì¹˜)")
        
        for i in tqdm(range(0, len(texts), MAX_BATCH_SIZE), desc="ğŸ’« DB ì—…ë°ì´íŠ¸"):
            end_idx = min(i + MAX_BATCH_SIZE, len(texts))
            vectorstore._collection.add(
                embeddings=embeddings[i:end_idx],
                documents=texts[i:end_idx],
                metadatas=metadatas[i:end_idx],
                ids=ids[i:end_idx]
            )
        
        print(f"âœ¨ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ (ì´ {len(texts)}ê°œ ë¬¸ì„œ)")
        return vectorstore

    @staticmethod
    def save_processed_file_info(csv_file):
        """ì²˜ë¦¬ëœ íŒŒì¼ ì •ë³´ë¥¼ DBì— ì €ì¥."""
        RAG_DB.objects.create(file_name=os.path.basename(csv_file), file_path=csv_file)

    @staticmethod
    def get_temp_embedding_path(file_name):
        """ì„ì‹œ ì„ë² ë”© íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not os.path.exists(RAGProcessor.TEMP_DIR):
            os.makedirs(RAGProcessor.TEMP_DIR)
        return os.path.join(RAGProcessor.TEMP_DIR, f"{os.path.basename(file_name)}.pkl")

    @staticmethod
    def save_temp_embeddings(file_name, data):
        """ì„ë² ë”© ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        temp_path = RAGProcessor.get_temp_embedding_path(file_name)
        with open(temp_path, 'wb') as f:
            pickle.dump(data, f)

    @staticmethod
    def load_temp_embeddings(file_name):
        """ì„ì‹œ ì €ì¥ëœ ì„ë² ë”© ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        temp_path = RAGProcessor.get_temp_embedding_path(file_name)
        if os.path.exists(temp_path):
            with open(temp_path, 'rb') as f:
                return pickle.load(f)
        return None

class RAGQuery:
    @staticmethod
    def create_qa_chain():
        """ê³µìœ ëœ DB_DIRì„ ì‚¬ìš©í•˜ì—¬ QA ì²´ì¸ ìƒì„±"""
        db_dir = RAGProcessor.DB_DIR
        vectorstore = Chroma(
            persist_directory=db_dir,
            embedding_function=OpenAIEmbeddings(
                model="text-embedding-3-small"
            ),
            collection_name="korean_dialogue"
        )
        
        # í•„í„° ì œê±°í•˜ê³  í…ŒìŠ¤íŠ¸
        retriever = vectorstore.as_retriever(
            search_kwargs={"k": 10},  # ìƒìœ„ 10ê°œ ê²°ê³¼
            filter={"emotion": "happy"},
        )
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì»¬ë ‰ì…˜ ì •ë³´ ì¶œë ¥
        print(f"ì»¬ë ‰ì…˜ ë‚´ ë¬¸ì„œ ìˆ˜: {vectorstore._collection.count()}")
        
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=1.1,
            n=3
        )

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        template = """Answer the question based on the following context.
        
        context : {context}
        
        User's message : {question}
        
        Please follow the rules below.
        
            1. When responding to my messages, maintain a gentle and    non-confrontational tone, as if I am speaking directly. 
               Rephrase my words in a warm and considerate manner to convey emotions and concerns respectfully. 
               Keep responses concise and focused on delivering my intended message.
            2. (Most Important) I am not talking to an AI; I am conversing with my partner. 
               Translate my words into a response of 30 characters or fewer that aligns with the specified tone.
            3. Speak in the following manner: gentle, warm, and considerate.
            4. always speak korean
            5. provide 3 examples of messages that can be used to respond to the user's message
            6. Don't use formal speech too stiffly, but make it cute and playful.

Read the user's message and rephrase it according to the specified style in the following format:  
Response format: Rephrased message1 | Rephrased message2 | Rephrased message3
"""
        
        prompt = ChatPromptTemplate.from_template(template)
        chain = prompt | llm
        
        return retriever, chain

    @staticmethod
    def get_answer(question: str):
        """DB_DIR íŒŒë¼ë¯¸í„° ì œê±°"""
        retriever, chain = RAGQuery.create_qa_chain()
        retrieved_docs = retriever.invoke(question)
        context = "\n".join([doc.page_content for doc in retrieved_docs])
        print(f"context: {context}")
        result = chain.invoke({
            "context": context,
            "question": question
        })
        
        return result.content
